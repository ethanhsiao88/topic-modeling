{"cells":[{"cell_type":"code","source":["# %pip install torch\n# %pip install transformers\n# %pip install flair\n# %pip install vaderSentiment\n# %pip install textblob"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3410a4c-dea8-4d80-b932-a64e47fc5797"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import flair\nflair_sentiment = flair.models.TextClassifier.load('en-sentiment')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"785c53d8-88d7-4820-8fba-9c0a0c97736c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import torch\nfrom transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\nfrom transformers import BertTokenizerFast, BertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nimport numpy as np\nimport random\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom pyspark.sql.functions import col\nimport pandas as pd\nimport calendar"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8bbbb95-ec14-4c42-8bcf-b5f783855a72"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def set_seed(seed: int):\n    \"\"\"\n    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n    installed).\n\n    Args:\n        seed (:obj:`int`): The seed to set.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    if is_torch_available():\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        # ^^ safe to call this function even if cuda is not available\n    if is_tf_available():\n        import tensorflow as tf\n\n        tf.random.set_seed(seed)\n\nset_seed(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"453cab09-d10c-437d-9693-20dc251c21a6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# the model we gonna train, base uncased BERT (https://huggingface.co/models?filter=text-classification)\nmodel_name = \"bert-base-uncased\"\nmax_length = 200 # max sequence length for each document/sentence sample"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fbb5917-d475-4a2a-9758-5121ad76dc95"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# load the tokenizer\ntokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc14eef1-b70c-455c-b15d-7e78c784a65d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c402b77b-683e-4576-a767-c2aef0ca9b10"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Read data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22121615-5bab-4b16-a855-6bda69bab42f"}}},{"cell_type":"code","source":["#Read data from widget\n\nBASE_PATH = \"a) Training Data Path\"\ndbutils.widgets.text(BASE_PATH, \"s3://ipsy-databricks-mlp/research/ethan/all_detractors_gb_gbplus_gbx_feb_to_jun.csv\")\nbase_path = dbutils.widgets.get(BASE_PATH)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bca7fc17-57ca-458d-a096-d1c24018a18a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#df = read('s3://ipsy-databricks-mlp/research/ethan/first1500detractorsmonolabeled.csv', ',')\n#df = read('s3://ipsy-databricks-mlp/research/ethan/alldetractorsmonolabeled.csv', ',')\n#df = spark.read.csv('s3://ipsy-databricks-mlp/research/ethan/all_detractors_gb_gbplus_gbx_feb_to_jun.csv', header=True)\n\ndf = spark.read.csv(base_path, header=True)\nprint('num rows: ', df.count())\n\ndf.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27a73239-1f25-4bad-9ccd-0e8750e1bc84"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3552bd6a-96b4-4d87-b0fc-a8975ecd3a3a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Preprocessing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af87cec4-698b-43a5-b2e2-9da67fcbdd6d"}}},{"cell_type":"code","source":["#rename columns\ndf = df.withColumnRenamed('How likely are you to recommend the Glam Bag to a friend?', 'nps')\ndf = df.withColumnRenamed('How likely are you to recommend Glam Bag Plus to a friend?', 'nps')\ndf = df.withColumnRenamed('How likely are you to recommend Glam Bag X to a friend?', 'nps')\ndf = df.withColumnRenamed('What is the most important reason for your recommendation answer?', 'comments')\ndf = df.withColumnRenamed('Start Date', 'start')\ndf = df.withColumnRenamed('End Date', 'end')\ndf = df.withColumnRenamed('Subscription', 'subscription')\ndf.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"835c1937-82c8-4504-889f-565e0844698f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Filter out null comments, make nps all ints\ndf = df.select('start', 'end', 'topic_type', 'nps', 'comments', 'subscription', 'userId')\ndf = df.filter(df[\"comments\"].isNotNull())\ndf = df.filter(df[\"topic_type\"].isNotNull())\ndf = df.replace(\"10 = Extremely likely\", '10', ['nps']).replace(\"0 = Not at all likely\", '0', ['nps']) # added new\ndf = df.withColumn('nps', df.nps.cast('int'))\ndf = df.filter(df[\"nps\"].isNotNull())\n\ndf.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed64c851-01c7-4ff7-8590-d667fb76d38f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pd = df.toPandas()\ndf_pd"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c84cc66-a6ac-4cf3-8ac2-2b89d34d844a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#only keep mono-labeled data\ndf_mono_labeled = df_pd[df_pd[\"topic_type\"].str.contains(\",\")==False]\ndf_mono_labeled"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"099426e6-2b41-4744-9783-8ebf31bf8153"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Replace weird syntax\n'''\nex: ‚Äô --> '\nex: ‚Äú --> \" (opening quote)\nex: ‚Äù --> \" (ending quote)\n'''\nweird_syntax = {\"‚Äô\": '\\'', \n                \"‚Äú\": '\\'', \n                \"‚Äù\": '\\'',\n                \"‚Äò\": '\\'',\n                \"‚Äö√Ñ√¥\": '\\'',\n                \"‚Äö√Ñ√∫\": '\\'',\n                \"‚Äö√Ñ√π\": '\\'',\n                \"‚Äî\": ' ',\n                \"‚Ä¶\": ' ',\n                \"Ô£ø√º¬ß‚àëÔ£ø√º√®√¶\": ' ',\n                \"‚Å∞\": ' ',\n                \"‚ù§\": ' ',\n                \"‚óç‚Ä¢·¥ó‚Ä¢‚óç\": ' ',\n                \"ü§∑‚Äç‚ôÄÔ∏è\": ' '\n               }\n\nfor index, item in df_mono_labeled['comments'].items():\n  for key in weird_syntax:\n    df_mono_labeled['comments'][index] = df_mono_labeled['comments'][index].replace(key, weird_syntax[key])\n  \ndf_mono_labeled.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b89d51e4-ea40-4792-a6f3-0078a9bd8b70"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Filter out random comments\nrandom = [\"na\", \"na \", \"no\", \"no \", \"Na\", \"Na \", \"No\", \"No \", \"NA\", \"NA \", \"NO\", \"NO \", \"n/a\", \"n/a \", \"N/A\", \"N/A \", \".\", \". \", \"?\", \"? \", \",\", \", \", \"!\", \"! \", \"..\", \".. \", \"...\", \"... \", \"....\", \".... \", \".....\", \"..... \", \" \", \"  \", \"   \", \"    \", \"     \"]\n\ndf_mono_labeled = df_mono_labeled[~df_mono_labeled['comments'].isin(random)]\ndf_mono_labeled"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d27d0f3b-6787-4f84-983b-094aa2fa74b1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Shift date and add month column\n\ndf_mono_labeled['date'] = pd.to_datetime(df_mono_labeled['end'], format='%Y-%m-%d')\ndf_mono_labeled['date_shifted'] = df_mono_labeled['date'] + pd.TimedeltaIndex( [-6]*len(df_mono_labeled.index), unit='d') #shift back 6 days\ndf_mono_labeled['month'] = pd.DatetimeIndex(df_mono_labeled['date_shifted']).month\ndf_mono_labeled['month'] = df_mono_labeled['month'].apply(lambda x: calendar.month_abbr[x])\ndf_mono_labeled = df_mono_labeled.drop(['date', 'date_shifted'], axis=1)\ndf_mono_labeled"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a72b363a-b856-4429-94cb-6d2e6f3ab717"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Add NPS type column (detractors, passives, and promoters)\ndf_mono_labeled['nps'] = df_mono_labeled['nps'].astype(int)\ndf_mono_labeled[\"nps_type\"] = df_mono_labeled[\"nps\"].apply(lambda x : 'detractor' if x <=6 else 'passive' if x <=8 else 'promotor')\ndf_mono_labeled['nps'] = df_mono_labeled['nps'].astype(str)\n\ndf_mono_labeled"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20c07e2b-812d-498a-80b7-fcf8b5755bc9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72d09ff8-12c0-4d6c-99eb-6ccccb23217d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Flair"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c6bb03a-e570-4718-8c6c-26ff4035266d"}}},{"cell_type":"code","source":["#Get comment score and type (POSITIVE or NEGATIVE) of each comment\n\ndef comment_score(row): \n  sentence = str(row['comments'])\n  s = flair.data.Sentence(sentence)\n  flair_sentiment.predict(s)\n  total_sentiment = s.labels\n  s = total_sentiment[0].to_dict()\n  return s['value'], s['confidence']\n\ndf_mono_labeled['comment_type'], df_mono_labeled['comment_score'] = zip(*df_mono_labeled.apply(comment_score, axis=1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4aad647-0918-41c4-97a0-b2608c395eea"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_mono_labeled['comment_score'] = df_mono_labeled['comment_score'] * 1000\ndf_mono_labeled[\"comment_score\"] = df_mono_labeled[\"comment_score\"].astype(int)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"070644ed-d2a5-48ad-94dc-35b2629c7624"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Filter out positive comments\n\ndf_neg = df_mono_labeled[(df_mono_labeled[\"comment_type\"]=='NEGATIVE')].sort_values(by = 'comment_score')\ndf_neg.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49666dd2-39d9-4b2c-94b0-4e6878d71c70"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print('num of non-null comments: ', df_mono_labeled.count())\nprint('num of non-null negative comments: ', df_neg.count())\nprint('percent of negative comments: ', df_neg.count()/df_mono_labeled.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77ea1c1d-532f-4291-8d7f-cb8e7cc51002"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7d9b213-d6a6-4f32-b0cd-95eb4db8e675"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Training Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"314365f2-f2bb-418c-9767-1b5cf7726e32"}}},{"cell_type":"code","source":["#Read data from widget\n\n#dbutils.widgets.removeAll()\n#dbutils.widgets.remove(\"Base Path\")\nTEST_SIZE = \"b) Test Size\"\ndbutils.widgets.dropdown(TEST_SIZE, \"0.2\", [\"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\"])\ntest_size = float(dbutils.widgets.get(TEST_SIZE))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cae9e3c8-d96d-4e46-8db7-14ac111a3422"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef read_comments(df, test_size=0.2):\n    labelencoder = LabelEncoder()\n    df['topic_type_label'] = labelencoder.fit_transform(df['topic_type']) #transforms topic type from strs to ints\n    documents = df.comments.tolist()\n    labels = df.topic_type_label.tolist()\n    return train_test_split(documents, labels, test_size=test_size, stratify=labels), labelencoder.classes_ \n      \n(train_texts, valid_texts, train_labels, valid_labels), target_names = read_comments(df_neg, test_size) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6b85421-816c-4dd5-9514-11c416a72ed8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(\"target names: \", target_names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc4f3fe6-4a09-44eb-bff7-69fbc25f2128"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# tokenize the dataset, truncate when passed `max_length`, \n# and pad with 0's when less than `max_length`\n# always tokenize after splitting\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=200)\nvalid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=200)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff8bc618-3b15-4c5b-8956-c44039967c8e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["class comment_dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n        item[\"labels\"] = torch.tensor([self.labels[idx]])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# convert our tokenized data into a torch Dataset\ntrain_dataset = comment_dataset(train_encodings, train_labels)\nvalid_dataset = comment_dataset(valid_encodings, valid_labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cff0ceb-c99c-4dd5-9519-e6fd40885e9c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# load the model and pass to CUDA\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))#.to(\"cuda\")\n#from transformers import AutoModelForSequenceClassification\n#model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(set(target_names)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b619973-a27a-4896-bdc4-1a739181f244"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    f1_scores = f1_score(labels, preds, average='weighted')\n    return {'accuracy': acc, 'f1_score': f1_scores,}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd53c5a0-7fda-4573-adbe-14bac5fcb0c7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Read data from widget\n\n#dbutils.widgets.removeAll()\n#dbutils.widgets.remove(\"Base Path\")\nNUM_EPOCHS = \"c) Num of Train Epochs\"\ndbutils.widgets.dropdown(NUM_EPOCHS, \"15\", [\"5\", \"10\", \"15\", \"20\"])\nnum_epochs = int(dbutils.widgets.get(NUM_EPOCHS))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a090596d-fe3a-4f47-8fd2-dda440d0f143"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["training_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=num_epochs,     # total number of training epochs\n    per_device_train_batch_size=32,  # batch size per device during training\n    per_device_eval_batch_size=32,   # batch size for evaluation\n    warmup_steps=10,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n    logging_steps=100,               # log & save weights each logging_steps\n    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cfe6df9-007d-410d-8242-1525fe2f222c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["trainer = Trainer(\n    model=model,                         # the instantiated Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=valid_dataset,          # evaluation dataset\n    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"871383d7-fabb-4dbf-b4d2-0fb5e6f412dd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# train the model\ntrainer.train()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3c8b5b2-31a4-432f-b861-3352a326d3c2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#clear prev model storage\n#! rm -rf results/checkpoint-*\n#! df -h /databricks/driver\n\n# evaluate the current model after training\ntrainer.evaluate() "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d69d9aeb-52be-4226-b5ff-39b076a0053e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d9f273d-9e7a-48fe-a4de-baf4c1822a62"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Save Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b6a8f0d-d6ff-4e40-91da-250482f5cb9a"}}},{"cell_type":"code","source":["# saving the fine tuned model & tokenizer - https://huggingface.co/transformers/main_classes/model.html\n\nmodel_path = \"sentiment-topic-bert-base-uncased\"\nmodel.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f560ab0-48e3-4130-914f-b78370521878"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["SAVE_PATH = \"d) Save Path\"\ndbutils.widgets.text(SAVE_PATH, \"dbfs:/mnt/ipsy-databricks-mlp/research/ethan/monolabeled-model-full-w-others-copy\")\nsave_path = dbutils.widgets.get(SAVE_PATH)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"623dbb9e-2a6c-4e7f-b78d-68e71bb13d87"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#save to amazon s3\ndbutils.fs.mv(\"file:/databricks/driver/sentiment-topic-bert-base-uncased\", save_path, recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"040c5c2d-e705-4d9e-9b8e-df78d76f33b4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#load saved model\ndbutils.fs.cp(save_path, \"file:/databricks/driver/sentiment-topic-bert-base-uncased\", recurse=True)\ntokenizer_2 = BertTokenizerFast.from_pretrained(model_path)\nmodel_2 = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(target_names))#.to(\"cuda\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acc041db-0733-4ef3-b703-5845d3d8d0a9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"687043b8-6c54-4697-9de6-b97fdcc754a7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Evaluating Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eb70f31-7136-4192-b01c-9448efc851eb"}}},{"cell_type":"code","source":["df_used = df_neg[:]\ndf_used"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"940013a1-acc5-44eb-bcf2-7e88f1541649"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_prediction_clean(text):\n    # prepare our text into tokenized sequence\n    inputs = tokenizer_2(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n    # perform inference to our model\n    outputs = model_2(**inputs)\n    # get output probabilities by doing softmax\n    probs = outputs[0].softmax(1)\n    # executing argmax function to get the candidate label\n    return target_names[probs.argmax()]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"627495d9-4a82-43c9-a7f8-3c8db85521cf"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ndef accuracy(y: list, pred: list):\n    # accuracy: (tp + tn) / (p + n)\n    from sklearn.metrics import accuracy_score\n    accuracy = accuracy_score(y, pred)    \n    return accuracy\n\ndef cm(y: list, pred: list):\n    from sklearn.metrics import confusion_matrix\n    return confusion_matrix(y, pred)  \n  \ndef confusion_matrix_plot(y, pred, normalize=False):\n    plot_confusion_matrix(y, pred, classes=target_names, normalize=normalize, title='Confusion matrix')\n\ndef plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    from sklearn.utils.multiclass import unique_labels\n    from sklearn.metrics import confusion_matrix\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n        yticks=np.arange(cm.shape[0]),\n        # ... and label them with the respective list entries\n        xticklabels=classes, yticklabels=classes,\n        title=title,\n        ylabel='True label',\n        xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d10b87d-67b4-4d93-959e-0562d532cc81"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca5b681a-ef2f-4322-85ed-92d2d67dd729"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####All Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36d26cf0-6768-4962-b366-61f922a6362d"}}},{"cell_type":"code","source":["df_used['predicted_label'] = df_used['comments'].apply(get_prediction_clean)\nactual_label = df_used['topic_type']\npred_label = df_used['predicted_label']\ndf_used"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0abced6a-cac9-4b1f-8d09-84f01b304e0d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# You can download results here!\ndf_used.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ddf228d-b6d5-4da7-87cd-9492461d9d25"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["confusion_matrix_plot(actual_label, pred_label)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f209ce5d-c3cd-41e1-9193-a06b435ea143"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["confusion_matrix_plot(actual_label, pred_label, normalize=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cecc23d4-e991-486e-bbc8-60881c14142c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n# accuracy = (tp + tn) / (tp + tn + fp + fn)\n# precision = tp / (tp + fp)   tp out of all labeled p\n# recall = tp / (tp + fn)      tp out of all actually p\n# f1 = weighted avg of precision and recall\nprint('accuracy: ', accuracy(actual_label, pred_label))\nprint()\nprint(classification_report(actual_label, pred_label))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"787d433f-d881-4b4c-b045-a6253386bf84"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a36536d8-acf7-42b9-9276-7fc58efa2827"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####Testing Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aca24af2-ca9b-413e-9369-744cbb7a32a0"}}},{"cell_type":"code","source":["testing_data_df = pd.DataFrame(target_names[valid_labels], columns = ['topic_type'])\ntesting_data_df['comments'] = valid_texts\ntesting_data_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1577e15e-e6bc-4122-8860-46d155dd9d82"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["testing_data_df['predicted_label'] = testing_data_df['comments'].apply(get_prediction_clean)\ntesting_data_actual_label = testing_data_df['topic_type']\ntesting_data_predicted_label = testing_data_df['predicted_label']\ntesting_data_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06316071-b58e-4e5e-85cb-1c05c39ff517"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["confusion_matrix_plot(testing_data_actual_label, testing_data_predicted_label)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67dcfd6b-0b21-4b19-b02c-475331dbf2a6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["confusion_matrix_plot(testing_data_actual_label, testing_data_predicted_label, normalize=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3b56b96-8f52-44d4-b57a-9557ef020bc7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# accuracy = (tp + tn) / (tp + tn + fp + fn)\n# precision = tp / (tp + fp)   tp out of all labeled p\n# recall = tp / (tp + fn)      tp out of all actually p\n# f1 = weighted avg of precision and recall\nprint('accuracy: ', accuracy(testing_data_actual_label, testing_data_predicted_label))\nprint()\nprint(classification_report(testing_data_actual_label, testing_data_predicted_label))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4bbf088d-cdad-4b7f-9551-f1c26a2a4c4e"}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.9.2","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"topic-modeling copy (training, productionized)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"experimentId":"4446428"},"language":"python","widgets":{"b) Test Size":{"nuid":"39660f43-f8dc-4253-8ee0-749a1ad305f8","currentValue":"0.2","widgetInfo":{"widgetType":"dropdown","name":"b) Test Size","defaultValue":"0.2","label":null,"options":{"widgetType":"dropdown","choices":["0.1","0.15","0.2","0.25","0.3"]}}},"c) Num of Train Epochs":{"nuid":"84c85aa6-33e3-4394-8273-61d5e701f2cc","currentValue":"15","widgetInfo":{"widgetType":"dropdown","name":"c) Num of Train Epochs","defaultValue":"15","label":null,"options":{"widgetType":"dropdown","choices":["5","10","15","20"]}}},"a) Training Data Path":{"nuid":"4712fd5d-43d4-4386-8af4-4a9288303647","currentValue":"s3://ipsy-databricks-mlp/research/ethan/all_detractors_gb_gbplus_gbx_feb_to_jun.csv","widgetInfo":{"widgetType":"text","name":"a) Training Data Path","defaultValue":"s3://ipsy-databricks-mlp/research/ethan/all_detractors_gb_gbplus_gbx_feb_to_jun.csv","label":null,"options":{"widgetType":"text","validationRegex":null}}},"d) Save Path":{"nuid":"62a9e850-ae07-48f4-b1e4-5a7531fc9f58","currentValue":"dbfs:/mnt/ipsy-databricks-mlp/research/ethan/monolabeled-model-full-w-others-copy","widgetInfo":{"widgetType":"text","name":"d) Save Path","defaultValue":"dbfs:/mnt/ipsy-databricks-mlp/research/ethan/monolabeled-model-full-w-others-copy","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":4659645}},"nbformat":4,"nbformat_minor":0}
